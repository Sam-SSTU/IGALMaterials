该课程主要为大家讲授如下的内容：
- 图形处理模型
- 序列处理模型


1. 图形处理模型
	1. AlexNet
		AlexNet是由 Geoffrey Hinton 的博士生 Alex Krizhevsky在2012年提出一款卷积神经网络模型。它采用ReLU激活函数、最大池化和Dropout，提升了特征的丰富性、有效防止了过拟合，并采用CUDA并行计算来快速完成计算任务。
		它的精度高，被认为是计算机视觉领域最具影响力的深度学习模型，被广泛应用于图像分类任务中。
		[[AlexNet.png]]
	2. ResNet
		Residual Neural Network简称ResNet，是由微软研究院的何凯明等四名华人提出的深度学习模型。ResNet的主要思想是在神经网络中增加了直连通道，解决深层网络的梯度消失和梯度爆炸问题。它的结构可以极大加速深层网络模型的训练，且具有非常好的推广性、在表征学习上效果极佳。这是继AlexNet之后计算机视觉和深度学习领域的又一里程碑。
		[[ResNet.png]]
2. 序列处理模型
	1. LAS
		Listen Attend and Spell简称LAS，于2016年由卡耐基梅隆的学者Chan和Google大脑的团队提出。和传统的语音识别系统不同，LAS使用多层RNN组成的Listener提取特征、主要由注意力机制组成的Speller输出识别的文字。虽然LAS的精度很高，但是由于需要结合上下文信息、无法进行流式的语音识别。
		[[LAS.png]]
	2. Tacotron-WaveNet
		Tacotron-Wavenet是第一个端到端的语音合成神经网络模型，于2017年由Google 大脑提出。它的核心是循环的seq2seq预测网络和注意力机制。在生成语音的过程中，Tacotron-Wavenet不仅捕捉了单词的发音，还能够体现人类语音的微妙变化，包括音量、语速和语调等。Tacotron-Wavenet也是近些年语音合成的主流模型。 
		[[Tacotron-WaveNet.png]]
	3. BERT
		Bidirectional Encoder Representations from Transformers简称BERT，是一项基于Transformer的双向编码表示技术。它在2018年由Google AI研究院提出。BERT是一种深度双向的、无监督的语言表示的，且仅使用纯文本语料库进行预训练的模型。它避免了word2vec、GloVe这样的上下文无关的词嵌入模型容易出现的词语歧义问题，能够根据上下文的句意对同一个词提供不同的词向量。
		BERT在被提出后成绩骄人，成为自然语言处理领域里程碑式的成就。目前该模型已经成为了自然语言处理工业应用的主流，大部分处理文本的人工智能任务都会采用BERT来完成。
		[[BERT.png]]